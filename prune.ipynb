{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.classifier import pointnet_cls\n",
    "import torch\n",
    "\n",
    "classifier = pointnet_cls.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward\n",
    "B = 4\n",
    "sample_data = torch.randn(B, 6, 1)\n",
    "unpruned_out = classifier(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Conv1d(6, 64, kernel_size=(1,), stride=(1,)), Conv1d(64, 128, kernel_size=(1,), stride=(1,)))\n",
      "Conv1d(6, 64, kernel_size=(1,), stride=(1,))\n",
      "Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.nn.utils import prune\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "module_list = list(classifier.named_modules())\n",
    "convs = [(module_list[i][1], module_list[i+1][1]) for i in range(len(module_list) - 1) if isinstance(module_list[i][1], nn.Conv1d) and isinstance(module_list[i+1][1], nn.Conv1d)]\n",
    "\n",
    "for conv_pair in convs:\n",
    "    print(conv_pair)\n",
    "    print(conv_pair[0])\n",
    "    pruned_weight = prune.ln_structured(conv_pair[0], 'weight', 0.5, 2, 1)\n",
    "    pruned_weight = prune.ln_structured(conv_pair[1], 'weight', 0.5, 2, 0)\n",
    "    print(pruned_weight)\n",
    "    break\n",
    "    prune.ln_structured(conv_pair[1], 'weight', 0.5, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn.utils import prune\n",
    "\n",
    "def prune_pointnet(pointnet):\n",
    "    module_list = list(classifier.named_modules())\n",
    "    convs = [(module_list[i][1], module_list[i+1][1]) \\\n",
    "            for i in range(len(module_list) - 1) if \\\n",
    "            isinstance(module_list[i][1], nn.Conv1d) \\\n",
    "            and isinstance(module_list[i+1][1], nn.Conv1d)\n",
    "            ]\n",
    "\n",
    "    for conv_pair in convs:\n",
    "        prune.ln_structured(conv_pair[0], 'weight', 0.5, 2, 1)\n",
    "        prune.ln_structured(conv_pair[1], 'weight', 0.5, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(31.6658, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune_pointnet(classifier)\n",
    "pruned_out = classifier(sample_data)\n",
    "torch.sum(torch.square(pruned_out - unpruned_out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-l2o",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
